# Pyspark
analysis data using pyspark
1-Data Consumption: Storing the malformed records in a different path without stopping the pipeline.
2-Clean messy data by split it in different columns
3-Aggregation: Aggregate the data and extract information about each country in another DataFrame 
